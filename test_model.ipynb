{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import copy\n",
    "import warnings\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss, LayerNorm\n",
    "from torch.nn import CrossEntropyLoss, LayerNorm, MSELoss, BCEWithLogitsLoss\n",
    "from torch.nn.utils import skip_init\n",
    "from typing import Optional, Tuple, Union, List, Callable, Dict, Any\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    "    CausalLMOutputWithPast,\n",
    "    SequenceClassifierOutputWithPast,\n",
    ")\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.utils import logging\n",
    "from transformers.generation.logits_process import LogitsProcessor\n",
    "from transformers.generation.utils import LogitsProcessorList, StoppingCriteriaList, GenerationConfig, ModelOutput\n",
    "from chatglm2.configuration_chatglm import ChatGLMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrefixEncoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The torch.nn model to encode the prefix\n",
    "    Input shape: (batch-size, prefix-length)\n",
    "    Output shape: (batch-size, prefix-length, 2*layers*hidden)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ChatGLMConfig,device: None):\n",
    "        super().__init__()\n",
    "        self.prefix_projection = config.prefix_projection\n",
    "        if self.prefix_projection:\n",
    "            # Use a two-layer MLP to encode the prefix\n",
    "            kv_size = config.num_layers * config.kv_channels * config.multi_query_group_num * 2\n",
    "            self.embedding = torch.nn.Embedding(config.pre_seq_len, kv_size)\n",
    "            self.trans = torch.nn.Sequential(\n",
    "                torch.nn.Linear(kv_size, config.hidden_size),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(config.hidden_size, kv_size)\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = torch.nn.Embedding(config.pre_seq_len,\n",
    "                                                config.num_layers * config.kv_channels * config.multi_query_group_num * 2)\n",
    "\n",
    "    def forward(self, prefix: torch.Tensor):\n",
    "        if self.prefix_projection:\n",
    "            prefix_tokens = self.embedding(prefix)\n",
    "            past_key_values = self.trans(prefix_tokens)\n",
    "        else:\n",
    "            past_key_values = self.embedding(prefix)\n",
    "        return past_key_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5, device=None, dtype=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.empty(normalized_shape, device=device, dtype=dtype))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        input_dtype = hidden_states.dtype\n",
    "        variance = hidden_states.to(torch.float32).pow(2).mean(-1, keepdim=True)\n",
    "        hidden_states = hidden_states * torch.rsqrt(variance + self.eps)\n",
    "\n",
    "        return (self.weight * hidden_states).to(input_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RMSNorm' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\electric\\chatglm\\test_model.ipynb 单元格 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/electric/chatglm/test_model.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m config \u001b[39m=\u001b[39m ChatGLMConfig(device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/electric/chatglm/test_model.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m RMSNorm(normalized_shape\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m)\u001b[39m.\u001b[39;49mdevice\n",
      "File \u001b[1;32mf:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RMSNorm' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "config = ChatGLMConfig(device = \"cpu\")\n",
    "RMSNorm(normalized_shape=256).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
